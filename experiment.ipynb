{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('/media/buslab/bed7bcae-c46d-4bde-874d-bdeb04d5dec9/NERO/DIP/final_project/defect-detection-and-segment-deep-learning/class_data/Val/powder_uncover/image/powder_uncover_converted_ 0374.png')\n",
    "\n",
    "# Load the bounding box data from the JSON file\n",
    "with open('/media/buslab/bed7bcae-c46d-4bde-874d-bdeb04d5dec9/NERO/DIP/final_project/defect-detection-and-segment-deep-learning/class_data/Val/powder_uncover/label/powder_uncover_converted_ 0374.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "if data['shapes'] != 1:\n",
    "    for i in range(len(data['shapes'])):\n",
    "        points = data['shapes'][i]['points']\n",
    "\n",
    "        x1, y1 = points[0]\n",
    "        x2, y2 = points[1]\n",
    "\n",
    "        # Create an ImageDraw object\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # paint and write the text with the bounding box points\n",
    "        # text\n",
    "        draw.text((x1, y1), \"x1, y1\", fill='red')\n",
    "        draw.text((x2, y2), \"x2, y2\", fill='red')\n",
    "        \n",
    "        # paint the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline='green')\n",
    "\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        # draw.rectangle([x1, y1, x2, y2], outline='green')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_set_dir = '../defect-detection-and-segment-deep-learning/class_data/Train'\n",
    "test_set_dir = '../defect-detection-and-segment-deep-learning/class_data/Val'\n",
    "\n",
    "# Define the transformations to apply to the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    # resize the image to 224x224\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    \n",
    "    # convert the rgb image to grayscale\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    # convert the image to a tensor\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define the custom dataset class\n",
    "class DefectDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None, mask:bool=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask = mask\n",
    "        self.class_names = ['powder_uncover', 'powder_uneven', 'scratch']\n",
    "        self.types = ['image']\n",
    "        self.image_filenames = []\n",
    "        # bounding box\n",
    "        self.labels = []\n",
    "        self.mask_filenames = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            # concatenate the image, label and mask directories\n",
    "            for type_name in self.types:\n",
    "                type_dir = os.path.join(class_dir, type_name)\n",
    "                for filename in os.listdir(type_dir):\n",
    "                    if filename.endswith('.png'):\n",
    "                        self.image_filenames.append(os.path.join(type_dir, filename))\n",
    "                        # read the label file for bounding box position\n",
    "\n",
    "                        self.mask_filenames.append(os.path.join(type_dir.replace('image', 'mask'), filename.replace('.png', '.png')))\n",
    "                        self.labels.append(class_name)\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_filenames[idx])\n",
    "        mask = Image.open(self.mask_filenames[idx]).convert('L')\n",
    "        \n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        if self.mask == True:    \n",
    "            return image, mask, label\n",
    "        else:\n",
    "            return image, label\n",
    "    \n",
    "# Load the training and test datasets\n",
    "trainset = DefectDetectionDataset(root_dir=train_set_dir, transform=transform)\n",
    "testset = DefectDetectionDataset(root_dir=test_set_dir, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Define the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(trainset.class_names))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### project target\n",
    "* You are asked to detect and segment the defects of manufacturing from given images. \n",
    "* You are given with  total 450  images and ground truth annotations(mask and bounding box positions).\n",
    "* You can use the image processing skills as well as deep learning methods for this homework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project steps\n",
    "* Step 1: Data preprocessing\n",
    "* Step 2: Data augmentation\n",
    "* Step 3: Model training: dectection and segmentation models\n",
    "* Step 4: Model evaluation with IoU and precision\n",
    "* Step 5: Creat a GUI for defect detection and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    # resize the image to 224x224\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    \n",
    "    # convert the rgb image to grayscale\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    # convert the image to a tensor\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define the custom dataset class\n",
    "class DefectDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None, mask:bool=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask = mask\n",
    "        self.class_names = ['powder_uncover', 'powder_uneven', 'scratch']\n",
    "        self.types = ['image']\n",
    "        self.image_filenames = []\n",
    "        # bounding box\n",
    "        self.labels = []\n",
    "        self.mask_filenames = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            # concatenate the image, label and mask directories\n",
    "            for type_name in self.types:\n",
    "                type_dir = os.path.join(class_dir, type_name)\n",
    "                for filename in os.listdir(type_dir):\n",
    "                    if filename.endswith('.png'):\n",
    "                        self.image_filenames.append(os.path.join(type_dir, filename))\n",
    "                        # read the label file for bounding box position\n",
    "\n",
    "                        self.mask_filenames.append(os.path.join(type_dir.replace('image', 'mask'), filename.replace('.png', '.png')))\n",
    "                        self.labels.append(class_name)\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_filenames[idx])\n",
    "        mask = Image.open(self.mask_filenames[idx]).convert('L')\n",
    "        \n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        if self.mask == True:    \n",
    "            return image, mask, label\n",
    "        else:\n",
    "            return image, label\n",
    "    \n",
    "# Load the training and test datasets\n",
    "trainset = DefectDetectionDataset(root_dir=train_set_dir, transform=transform)\n",
    "testset = DefectDetectionDataset(root_dir=test_set_dir, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Define the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(trainset.class_names))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.63it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.21it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 37.60it/s]\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s]\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.73it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy train images done\n",
      "copy val images done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "\n",
    "yolo_train_image_path = \"../defect-detection-and-segment-deep-learning/yolov7/defect/images/train/\"\n",
    "yolo_val_image_path = \"../defect-detection-and-segment-deep-learning/yolov7/defect/images/val/\"\n",
    "yolo_image_path = \"../defect-detection-and-segment-deep-learning/yolov7/defect/\"\n",
    "\n",
    "pathlib.Path(yolo_train_image_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(yolo_val_image_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_set_dir = '../defect-detection-and-segment-deep-learning/class_data/Train'\n",
    "test_set_dir = '../defect-detection-and-segment-deep-learning/class_data/Val'\n",
    "\n",
    "class_names = ['powder_uncover', 'powder_uneven', 'scratch']\n",
    "types = ['image']\n",
    "yolo_csv = pd.DataFrame(\n",
    "    columns=[\"category\", \"x\", \"y\", \"w\", \"h\", \"image_name\", \"set_type\", \"image_path\"])\n",
    "\n",
    "rename = False\n",
    "save = True\n",
    "copy = True\n",
    "\n",
    "# convert the label to yolo format\n",
    "\n",
    "\n",
    "def yolo_format(convert_img_file: str, save_img_file_name: str, save: bool = False):\n",
    "\n",
    "    label_path = convert_img_file.replace(\n",
    "        \"image\", \"label\").replace(\".png\", \".json\")\n",
    "    image_name = convert_img_file.split(\"/\")[-1]\n",
    "\n",
    "    with open(label_path, \"r\") as file:\n",
    "        json_file = json.load(file)\n",
    "\n",
    "    width, height = Image.open(convert_img_file).size\n",
    "\n",
    "    for annotation in json_file[\"shapes\"]:\n",
    "        if annotation[\"label\"] == \"powder_uncover\":\n",
    "            category_id = 0\n",
    "        elif annotation[\"label\"] == \"powder_uneven\":\n",
    "            category_id = 1\n",
    "        else:\n",
    "            category_id = 2\n",
    "        points = annotation[\"points\"]\n",
    "\n",
    "        # point[0] is left top of the bounding box\n",
    "        # point[1] is right bottom of the bounding box\n",
    "\n",
    "        x_min, y_min = points[0]\n",
    "        x_max, y_max = points[1]\n",
    "\n",
    "        # convert the bounding box to yolo format\n",
    "        x = (x_min + (x_max-x_min)/2) * 1.0 / width\n",
    "        y = (y_min + (y_max-y_min)/2) * 1.0 / height\n",
    "        w = (x_max-x_min) * 1.0 / width\n",
    "\n",
    "        # the height have nagative value, so we need to use abs() to get the positive value\n",
    "        h = abs((y_max-y_min) * 1.0 / height)\n",
    "\n",
    "        yolo_format_data = str(category_id) + \" \" + str(x) + \\\n",
    "            \" \" + str(y) + \" \" + str(w) + \" \" + str(h)\n",
    "\n",
    "        yolo_csv.loc[len(yolo_csv)] = [category_id, x, y, w, h,\n",
    "                                       image_name, save_img_file_name, convert_img_file]\n",
    "\n",
    "        # save the bounding box and category_id to a text file\n",
    "        # name is the same as the image name\n",
    "\n",
    "        if save == True:\n",
    "\n",
    "            with open(yolo_train_image_path.replace(\"images\", \"labels\").replace(\"train\", save_img_file_name) + image_name.replace(\".png\", \".txt\"), \"a\") as file:\n",
    "                file.write(yolo_format_data)\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "    if save == True:\n",
    "        # save the image path to a text file\n",
    "        with open(yolo_image_path + f\"{ save_img_file_name }.txt\", \"a\") as file:\n",
    "            file.write(f\"./images/{ save_img_file_name }/\" + image_name)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "# rename the image, label and mask files\n",
    "def rename_files(dataset_dir: str):\n",
    "\n",
    "    for dataset in [dataset_dir]:\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(dataset, class_name)\n",
    "            # concatenate the image, label and mask directories\n",
    "            for type_name in types:\n",
    "                type_dir = os.path.join(class_dir, type_name)\n",
    "                for filename in tqdm(os.listdir(type_dir)):\n",
    "\n",
    "                    # rename the image name with class + image name\n",
    "                    # remove file name with space\n",
    "\n",
    "                    if rename == True:\n",
    "                        # rename the image name with class + image name\n",
    "                        os.rename(\n",
    "                            src=f\"{type_dir}/{filename}\", dst=f\"{type_dir}/{class_name}_{filename.replace(' ', '').lower()}\")\n",
    "\n",
    "                        # rename the label name with class + label name\n",
    "                        os.rename(src=f\"{type_dir.replace('image', 'label')}/{filename.replace('.png', '.json')}\",\n",
    "                                  dst=f\"{type_dir.replace('image', 'label')}/{class_name}_{filename.replace('.png', '.json').replace(' ', '').lower()}\")\n",
    "\n",
    "                        # rename the mask name with class + mask name\n",
    "                        os.rename(src=f\"{type_dir.replace('image', 'mask')}/{filename}\",\n",
    "                                  dst=f\"{type_dir.replace('image', 'mask')}/{class_name}_{filename.replace(' ', '').lower()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if rename == True:\n",
    "\n",
    "        rename_files(dataset_dir=train_set_dir)\n",
    "        rename_files(dataset_dir=test_set_dir)\n",
    "\n",
    "    for dataset in [train_set_dir, test_set_dir]:\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(dataset, class_name)\n",
    "            # concatenate the image, label and mask directories\n",
    "            for type_name in types:\n",
    "                type_dir = os.path.join(class_dir, type_name)\n",
    "                for filename in tqdm(os.listdir(type_dir)):\n",
    "\n",
    "                    if dataset == train_set_dir:\n",
    "                        yolo_format(\n",
    "                            convert_img_file=f\"{type_dir}/{filename}\", save_img_file_name='train', save=save)\n",
    "                    else:\n",
    "                        yolo_format(\n",
    "                            convert_img_file=f\"{type_dir}/{filename}\", save_img_file_name='val', save=save)\n",
    "\n",
    "    if copy == True:\n",
    "        for dataset in [\"train\", \"val\"]:\n",
    "            for image_paths in yolo_csv.query(f\"set_type == '{dataset}'\")[\"image_path\"].unique():\n",
    "                # print(image_paths)\n",
    "                shutil.copy(image_paths, yolo_image_path +\n",
    "                            f\"images/{dataset}/\")\n",
    "            print(f\"copy {dataset} images done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using str.strip to remove space of with class name dictionary file name\n",
    "import os, shutil\n",
    "import pathlib\n",
    "\n",
    "# recusive the following folder and save file name in list\n",
    "Train_folder ='/media/buslab/bed7bcae-c46d-4bde-874d-bdeb04d5dec9/NERO/DIP/final_project/defect-detection-and-segment-deep-learning/class_data/Val/poser_uneven/'\n",
    "\n",
    "train_file_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(Train_folder):\n",
    "    for file in files:\n",
    "        train_file_list.append(file.strip().replace('.png', '').replace('.json', ''))\n",
    "\n",
    "# 找出檔案出現次數小於 3 次的檔案\n",
    "for i in train_file_list:\n",
    "    if train_file_list.count(i) < 3:\n",
    "        print(i)\n",
    "        \n",
    "# for i in train_file_list:\n",
    "#     if train_file_list.count(i) > 3:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('dip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95682e3b17397ec86f7197f5db473d6bf5c108e5e4327ec68d94866d6630a2c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
